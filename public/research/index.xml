<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Researches on CNIEL - University of Delaware</title>
    <link>http://localhost:1313/~ajbrock/research/</link>
    <description>Recent content in Researches on CNIEL - University of Delaware</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Aug 2021 00:59:28 -0400</lastBuildDate><atom:link href="http://localhost:1313/~ajbrock/research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>News and Recent Research</title>
      <link>http://localhost:1313/~ajbrock/research/news/</link>
      <pubDate>Tue, 24 Aug 2021 00:59:28 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/news/</guid>
      <description>July 2022 –Dr. Grace McIlvain presents joint work from the Prof. Johnson&amp;rsquo;s Mechanical Neuroimaging Lab (MNL) instigated by MNL&amp;rsquo;s Rebecca Clements (undergraduate thesis) and assisted by César: “Mechanical property-based brain age prediction using artificial neural networks”, World Congress of Biomechanics, Taipei, Taiwan. Journal version to be submitted soon!
June 2022 —César passes the Ph.D. qualifying examination.
—Alex Mulrooney starts the (undergraduate) Summer Scholars Program
—Karen Andrea Fonseca, B.S. (Industrial University of Santander, Bucaramanga, Colombia), joins us as a visiting research working on application of contrastive learning representations for improving detection of diffuse phenomena in astronomical images in collaboration with Prof.</description>
    </item>
    
    <item>
      <title>Interpretable maximal discrepancies metrics for analyzing and improving generative models</title>
      <link>http://localhost:1313/~ajbrock/research/discrepancies/</link>
      <pubDate>Wed, 14 Apr 2021 00:59:28 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/discrepancies/</guid>
      <description>Overview Divergence measures quantify the dissimilarity, including the distance, between distributions and are fundamental to hypothesis testing, information theory, and the estimation and criticism of statistical models. Recently, there has been renewed interest in divergences in the context of generative adversarial neural networks (GANs). While a multitude of divergences exist, they vary in their characteristics. Importantly, not all divergences are equally interpretable: a divergence between samples is considered interpretable if it directly answers the question “Which instances best exhibit the discrepancy between the samples?</description>
    </item>
    
    <item>
      <title>Advancing machine learning for neuroimaging through topology-aware signal processing</title>
      <link>http://localhost:1313/~ajbrock/research/graphs/</link>
      <pubDate>Sat, 01 Feb 2020 00:59:28 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/graphs/</guid>
      <description>The proposed work plan is to develop machine learning techniques to work directly with graph signal processing techniques in the context of neuroimaging. The goal is to leverage information in the form of the topology of the signal sensors or measurement locations to refine the neural signal representations in order to improve the statistical power of tests for distinguishing differences between conditions or stimuli. The project’s scope includes the formulation, mathematical and statistical analysis, and initial validation of the proposed methodology.</description>
    </item>
    
    <item>
      <title>Improving reference prioritisation with PICO recognition</title>
      <link>http://localhost:1313/~ajbrock/research/pico/</link>
      <pubDate>Sat, 01 Jun 2019 00:59:28 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/pico/</guid>
      <description>Overview 
Machine learning can assist with multiple tasks during systematic reviews to facilitate the rapid retrieval of relevant references during screening and to identify and extract information relevant to the study characteristics, which include the PICO elements of patient/population, intervention, comparator, and outcomes.

A publicly available corpus of PICO annotations on biomedical abstracts is used to train a named entity recognition model, which is implemented as a recurrent neural network.</description>
    </item>
    
    <item>
      <title>Quantifying the informativeness of similarity measurements</title>
      <link>http://localhost:1313/~ajbrock/research/informativeness/</link>
      <pubDate>Fri, 17 Mar 2017 21:25:29 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/informativeness/</guid>
      <description>Overview Choosing the particulars of a data representation is crucial for the successful application of machine learning techniques. In the unsupervised case, there is a lack of measures that can be used to compare different parameter choices that affect the representation. In this paper, we describe an unsupervised measure for quantifying the &amp;lsquo;informativeness&amp;rsquo; of correlation matrices formed from the pairwise similarities or relationships among data instances.
The measure quantifies the heterogeneity of the correlations and is defined as the distance between a correlation matrix and the nearest correlation matrix with constant off-diagonal entries.</description>
    </item>
    
    <item>
      <title>Learning Recurrent Waveforms within EEGs</title>
      <link>http://localhost:1313/~ajbrock/research/eegs/</link>
      <pubDate>Thu, 28 Apr 2016 22:42:02 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/eegs/</guid>
      <description>Overview When experts analyze EEGs they look for landmarks in the traces corresponding to established patterns such as oscillatory and phasic events of particular frequency or morphology. Long records motivate automated analysis techniques. Automation techniques often require design choices such as wavelet family or number of bandpass filters. To overcome this, we explore a modeling approach that automatically learns recurrent temporal waveforms within EEG traces. The estimation is based on a multiple-input, single-output linear model with sparsely excited inputs.</description>
    </item>
    
    <item>
      <title>Neural Decoding with Kernel-based Metric Learning</title>
      <link>http://localhost:1313/~ajbrock/research/neural_decoding/</link>
      <pubDate>Mon, 28 Apr 2014 23:19:06 -0400</pubDate>
      
      <guid>http://localhost:1313/~ajbrock/research/neural_decoding/</guid>
      <description>Overview Given a sample of data points, we often assume the points reside in some space in which we can measure distances between pairs of points. From these measurements we can understand which points are close to each other. Nearby points are often assumed to share characteristics. This assumption is the foundation of nearest-neighbor classification and regression as well as clustering.
The function that measures the distance between pairs of points in a particular space is called a distance metric.</description>
    </item>
    
  </channel>
</rss>
